{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Opencv proj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrYGuWz9nXup8U70wVKZzg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jkanishkha0305/Covid-19/blob/main/Opencv_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8tx3J2POxZZ"
      },
      "source": [
        "Install face_recognition library\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ejSd-ye29vs",
        "outputId": "bf9b90d2-6960-4631-da61-c63fe70bdde8"
      },
      "source": [
        "!pip install face_recognition\n",
        "%cd face_recognition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "/content/face_recognition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGxq3meWGn8B"
      },
      "source": [
        "Training from the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrk8fQbMGp9-",
        "outputId": "0098df4b-bce2-4424-d7e7-2d374189b37a"
      },
      "source": [
        "import face_recognition\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from IPython.display import display\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "face_1 = face_recognition.load_image_file(\"vijay.jpg\")\n",
        "face_1_encoding = face_recognition.face_encodings(face_1)[0]\n",
        "\n",
        "face_2 = face_recognition.load_image_file(\"nirbhaya.jpg\")\n",
        "face_2_encoding = face_recognition.face_encodings(face_2)[0]\n",
        "\n",
        "face_3 = face_recognition.load_image_file(\"kanishkha.jpg\")\n",
        "face_3_encoding = face_recognition.face_encodings(face_3)[0]\n",
        "\n",
        "known_face_encodings = [\n",
        "    face_1_encoding,\n",
        "    face_2_encoding,\n",
        "    face_3_encoding,\n",
        "]\n",
        "known_face_names = [\n",
        "    \"Vijay Gottipati\",\n",
        "    \"Nirbhay Reddy\",\n",
        "    \"J.Kanishkha\",\n",
        "    \"Pikachu\"\n",
        "]\n",
        "print(\"Done learning and creating profiles\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done learning and creating profiles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ahlm3hekJMv4"
      },
      "source": [
        "Attendance Register\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6ziyRsvJQPw"
      },
      "source": [
        "def makeAttendanceEntry(name):\n",
        "    with open('attendance_list.csv','r+') as f:\n",
        "        allLines = f.readlines()\n",
        "        attendanceList = []\n",
        "        for line in allLines:\n",
        "            entry = line.split(',')\n",
        "            attendanceList.append(entry[0])\n",
        "        if name not in attendanceList:\n",
        "            now = datetime.now()\n",
        "            dtString = now.strftime('%d/%b/%Y, %H:%M:%S')\n",
        "            f.writelines(f'\\n{name},{dtString}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqXtHywoJWNU"
      },
      "source": [
        "Face Recognition and attendance entry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG3-c96l425d"
      },
      "source": [
        "file_name = \"unknown_pk.jpg\"\n",
        "unknown_image = face_recognition.load_image_file(file_name)\n",
        "unknown_image_to_draw = cv2.imread(file_name)\n",
        "\n",
        "face_locations = face_recognition.face_locations(unknown_image)\n",
        "face_encodings = face_recognition.face_encodings(unknown_image, face_locations)\n",
        "\n",
        "pil_image = Image.fromarray(unknown_image)\n",
        "draw = ImageDraw.Draw(pil_image)\n",
        "\n",
        "for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
        "    # See if the face is a match for the known face(s)\n",
        "    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "\n",
        "    name = \"Unknown\"\n",
        "\n",
        "    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
        "    best_match_index = np.argmin(face_distances)\n",
        "    if matches[best_match_index]:\n",
        "        name = known_face_names[best_match_index]\n",
        "\n",
        "    # Draw a box around the face using the Pillow module\n",
        "    cv2.rectangle(unknown_image_to_draw,(left, top), (right, bottom), (0,255,0),3 )\n",
        "    draw.rectangle(((left, top), (right, bottom)), outline=(0, 255, 255))\n",
        "    cv2.putText(unknown_image_to_draw,name,(left,top-20), cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2,cv2.LINE_AA)\n",
        "    print(name)\n",
        "    makeAttendanceEntry(name)\n",
        "\n",
        "# display(pil_image)\n",
        "cv2_imshow(unknown_image_to_draw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF1qtkExPEms"
      },
      "source": [
        "Video Capture(Test)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzmNWPAGU_Cn"
      },
      "source": [
        "path = 'face_recognition'\n",
        "images = []\n",
        "classNames = []\n",
        "myList = os.listdir('face_recognition')\n",
        "print(myList)\n",
        "for c2 in myList:\n",
        "  curImg = cv2.imread(f'{path}/{c2}')\n",
        "  images.append(curImg)\n",
        "  classNames.append(os.path.splitext(c2)[0])\n",
        "print(classNames)\n",
        "\n",
        "def findEncodings(images):\n",
        "  encodeList = []\n",
        "  for img in images:\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    encode = face_recognition.face_encodings(img)[0]\n",
        "    encodeList.append(encode)\n",
        "  return encodeList\n",
        "\n",
        "encodeListKnown = findEncodings(images)\n",
        "print('Encoding complete')\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "  success,img = cap.read()\n",
        "  imgS = cv2.resize(img,(0,0),None,0.25,0.25)\n",
        "  imgS = cv2.cvtColor(imgS,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  facesCurFrame = face_recognition.face_locations(imgS)\n",
        "  encodesCurFrame = face_recognition.face_encodings(imgS,facesCurFrame)\n",
        "\n",
        "  for encodeFace,faceLoc in zip(encodesCurFrame,facesCurFrame):\n",
        "    matches = face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
        "    faceDis = face_recognition.fcae_distance(encodeListKnown,encodeFace)\n",
        "    print(faceDis)\n",
        "    matchIndex = np.argmin(faceDis)\n",
        "\n",
        "    if matches[matchIndex]:\n",
        "      name = classNames[matchIndex].upper()\n",
        "      print(name)\n",
        "      y1,x2,y2,x1 = faceLoc\n",
        "      y1,x2,y2,x1 = y1*4,x2*4,y2*4,x1*4\n",
        "      cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "      cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
        "      cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
        "\n",
        "  cv2.imshow('Webcam',img)\n",
        "  cv2.waitKey(1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qv9vrvG5cRq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}